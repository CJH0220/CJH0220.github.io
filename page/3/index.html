<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>CJH's blog - CJH's blog</title><meta name="author" content="CJH"><meta name="copyright" content="CJH"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Hello,my friends">
<meta property="og:type" content="website">
<meta property="og:title" content="CJH&#39;s blog">
<meta property="og:url" content="http://cjh0220.github.io/page/3/index.html">
<meta property="og:site_name" content="CJH&#39;s blog">
<meta property="og:description" content="Hello,my friends">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2022/09/08/vbOo6J.jpg">
<meta property="article:author" content="CJH">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2022/09/08/vbOo6J.jpg"><link rel="shortcut icon" href="/img/CJH.png"><link rel="canonical" href="http://cjh0220.github.io/page/3/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CJH\'s blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-09-09 09:58:01'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s1.ax1x.com/2022/09/08/vbOo6J.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">51</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://s1.ax1x.com/2022/09/08/vqcdVs.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">CJH's blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">CJH's blog</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/cjh0220" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1005741898@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2022/09/08/%E6%AE%8B%E5%B7%AE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="残差神经网络"><img class="post_bg" src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="残差神经网络"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/09/08/%E6%AE%8B%E5%B7%AE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="残差神经网络">残差神经网络</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-09-08T14:22:42.000Z" title="发表于 2022-09-08 22:22:42">2022-09-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">链接：
一文读懂残差网络
残差网络的由来
残差操作这一思想起源于论文《Deep Residual Learning for Image Recognition》，目前的引用量已达3万多。这篇文章发现，如果存在某个层的网络是当前最优的网络，那么可以构造一个更深的网络，其最后几层仅是该网络第层输出的恒等映射(Identity Mapping)，就可以取得与一致的结果；也许还不是所谓“最佳层数”，那么更深的网络就可以取得更好的结果。总而言之，与浅层网络相比，更深的网络的表现不应该更差。但是如下图所示，56层的神经网络表现明显要比20层的差。证明更深的网络在训练过程中的难度更大，因此作者提出了残差网络的思想。
网络层数加深导致的训练问题
残差网络的定义
残差网络依旧让非线形层满足  ，然后从输入直接引入一个短连接到非线形层的输出上，使得整个映射变为

这就是残差网路的核心公式，换句话说，残差是网络搭建的一种操作，任何使用了这种操作的网络都可以称之为残差网络。
一个具体的残差模块的定义如下图：
残差模块（由于先敲公式后引得图，容易混淆，图中的F(x)就是上文所说的H(x,w)，下面也一样替换）
 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/09/08/XGboost%E7%AE%97%E6%B3%95/" title="XGboost算法"><img class="post_bg" src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="XGboost算法"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/09/08/XGboost%E7%AE%97%E6%B3%95/" title="XGboost算法">XGboost算法</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-09-08T14:19:25.000Z" title="发表于 2022-09-08 22:19:25">2022-09-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">XGBoost
1. 什么是XGBoost
XGBoost是陈天奇等人开发的一个开源机器学习项目，高效地实现了GBDT算法并进行了算法和工程上的许多改进，被广泛应用在Kaggle竞赛及其他许多机器学习竞赛中并取得了不错的成绩。
说到XGBoost，不得不提GBDT(Gradient Boosting Decision Tree)。因为XGBoost本质上还是一个GBDT，但是力争把速度和效率发挥到极致，所以叫X (Extreme) GBoosted。包括前面说过，两者都是boosting方法。
1.1 XGBoost树的定义
先来举个例子，我们要预测一家人对电子游戏的喜好程度，考虑到年轻和年老相比，年轻更可能喜欢电子游戏，以及男性和女性相比，男性更喜欢电子游戏，故先根据年龄大小区分小孩和大人，然后再通过性别区分开是男是女，逐一给各人在电子游戏喜好程度上打分，如下图所示。

就这样，训练出了2棵树tree1和tree2，类似之前gbdt的原理，两棵树的结论累加起来便是最终的结论，所以小孩的预测分数就是两棵树中小孩所落到的结点的分数相加：2 + 0.9 = 2.9。爷爷的预测分数同理：-1 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/09/08/GBDT%E7%AE%97%E6%B3%95/" title="GBDT算法"><img class="post_bg" src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GBDT算法"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/09/08/GBDT%E7%AE%97%E6%B3%95/" title="GBDT算法">GBDT算法</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-09-08T14:11:21.000Z" title="发表于 2022-09-08 22:11:21">2022-09-08</time></span></div><div class="content">GBDT算法 （梯度提升决策树）
1.GBDT算法的过程
1.1Boosting思想
Boosting方法训练基分类器时采用串行的方式，各个基分类器之间有依赖。它的基本思路是将**基分类器层层叠加，每一层在训练的时候，对前一层基分类器分错的样本，给予更高的权重。**测试时，根据各层分类器的结果的加权得到最终结果。
Bagging与Boosting的串行训练方式不同，Bagging方法在训练过程中，各基分类器之间无强依赖，可以进行并行训练。
GBDT(Gradient Boosting Decision Tree)，全名叫梯度提升决策树，使用的是Boosting的思想。
1.2GBDT原理
GBDT的原理很简单，就是所有弱分类器的结果相加等于预测值，然后下一个弱分类器去拟合误差函数对预测值的残差(这个残差就是预测值与真实值之间的误差)。当然了，它里面的弱分类器的表现形式就是各棵树。
举一个非常简单的例子，比如我今年30岁了，但计算机或者模型GBDT并不知道我今年多少岁，那GBDT咋办呢？

它会在第一个弱分类器（或第一棵树中）随便用一个年龄比如20岁来拟合，然后发现误差有10岁；
接下来 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/09/08/SVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95/" title="SVM支持向量机算法"><img class="post_bg" src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SVM支持向量机算法"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/09/08/SVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95/" title="SVM支持向量机算法">SVM支持向量机算法</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-09-08T13:05:40.000Z" title="发表于 2022-09-08 21:05:40">2022-09-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">1.SVM
支持向量机（support vector machines，SVM）是一种二分类模型，它将实例的特征向量映射为空间中的一些点，SVM 的目的就是想要画出一条线，以 “最好地” 区分这两类点，以至如果以后有了新的点，这条线也能做出很好的分类。SVM 适合中小型数据样本、非线性、高维的分类问题。
SVM 最早是由 Vladimir N. Vapnik 和 Alexey Ya. Chervonenkis 在1963年提出，目前的版本（soft margin）是由 Corinna Cortes 和 Vapnik 在1993年提出，并在1995年发表。深度学习（2012）出现之前，SVM 被认为机器学习中近十几年来最成功，表现最好的算法。
1.1 SVM 基本概念
将实例的特征向量（以二维为例）映射为空间中的一些点，如下图的实心点和空心点，它们属于不同的两类。SVM 的目的就是想要画出一条线，以“最好地”区分这两类点，以至如果以后有了新的点，这条线也能做出很好的分类。

Q1：能够画出多少条线对样本点进行区分？
答：线是有无数条可以画的，区别就在于效果好不好，每条线都可以叫做一个划分 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/09/08/SMOTE%E8%BF%87%E9%87%87%E6%A0%B7%E7%AE%97%E6%B3%95%E3%80%81/" title="SMOTE过采样算法"><img class="post_bg" src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SMOTE过采样算法"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/09/08/SMOTE%E8%BF%87%E9%87%87%E6%A0%B7%E7%AE%97%E6%B3%95%E3%80%81/" title="SMOTE过采样算法">SMOTE过采样算法</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-09-08T13:03:57.000Z" title="发表于 2022-09-08 21:03:57">2022-09-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">一、问题背景：类别不平衡
从模型的训练过程来看
​		从训练模型的角度来说，如果某类的样本数量很少，那么这个类别所提供的“信息”就太少。
​        使用经验风险（模型在训练集上的平均损失）最小化作为模型的学习准则。设损失函数为0-1 loss（这是一种典型的均等代价的损失函数），那么优化目标就等价于错误率最小化（也就是accuracy最大化）。考虑极端情况：1000个训练样本中，正类样本999个，负类样本1个。训练过程中在某次迭代结束后，模型把所有的样本都分为正类，虽然分错了这个负类，但是所带来的损失实在微不足道，accuracy已经是99.9%，于是满足停机条件或者达到最大迭代次数之后自然没必要再优化下去，ok，到此为止，训练结束！
​        于是这个模型没有学习到如何去判别出少数类。
从模型的预测过程来看
​		考虑二项Logistic回归模型。输入一个样本 x ，模型输出的是其属于正类的概率 y’ 。当 y’&gt;0.5时，模型判定该样本属于正类，否则就是属于反类。
​		为什么是0.5呢？可以认为模型是出于最大后验概率决策的角度考虑的，选择了0.5意味着当模型 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/09/08/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E7%AE%80%E8%BF%B0/" title="聚类算法简述"><img class="post_bg" src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="聚类算法简述"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/09/08/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E7%AE%80%E8%BF%B0/" title="聚类算法简述">聚类算法简述</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-09-08T13:02:38.000Z" title="发表于 2022-09-08 21:02:38">2022-09-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">一、K-Means(K均值)聚类
算法步骤：
(1) 首先我们选择一些类/组，并随机初始化它们各自的中心点。中心点是与每个数据点向量长度相同的位置。这需要我们提前预知类的数量(即中心点的数量)。
(2) 计算每个数据点到中心点的距离，数据点距离哪个中心点最近就划分到哪一类中。
(3) 计算每一类中中心点作为新的中心点。
(4) 重复以上步骤，直到每一类中心在每次迭代后变化不大为止。也可以多次随机初始化中心点，然后选择运行结果最好的一个。
下图演示了K-Means进行分类的过程：


优点

速度快，计算简便


缺点

我们必须提前知道数据有多少类/组。



K-Medians是K-Means的一种变体，是用数据集的中位数而不是均值来计算数据的中心点。
K-Medians的优势是使用中位数来计算中心点不受异常值的影响；缺点是计算中位数时需要对数据集中的数据进行排序，速度相对于K-Means较慢。
二、均值漂移聚类
均值漂移聚类是基于滑动窗口的算法，来找到数据点的密集区域。这是一个基于质心的算法，通过将中心点的候选点更新为滑动窗口内点的均值来完成，来定位每个组/类的中心点。然后对这些候 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/09/08/Batch-Size%E8%A7%A3%E6%9E%90/" title="Batch-Size解析"><img class="post_bg" src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Batch-Size解析"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/09/08/Batch-Size%E8%A7%A3%E6%9E%90/" title="Batch-Size解析">Batch-Size解析</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-09-08T13:01:06.000Z" title="发表于 2022-09-08 21:01:06">2022-09-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">1.Batch Size 是什么？
Batch Size指的是一次训练所选取的样本数，
Batch Size的大小影响模型的优化程度和速度。

2.Batch Size 对训练效果的影响

当Batch Size太小时，比如Batch Size=1。一次迭代只需对一个样本进行计算，因此单次迭代速度很快，可用于在线学习。在实际过程中，由于单个样本的随机性，一方面，训练会剧烈波动；一方面， 这种波动可能使训练到达更好的局部最小值。
当Batch Size增大时，GPU的利用率会提高，对于相同的数据量处理的速度会更快一些。与此同时，Batch Size越大，其确定的下降方向越准，网络训练（收敛）的更快。
当Batch Size太大时，比如每次迭代更新使用所有的训练样本。那么迭代速度就会非常慢，甚至会出现训练不动的情况。

3.合理增大Batch Size 的好处
在合理范围内增大Batch Size 的好处在以下几个方面：

一次训练多组数据，内存利用率提高；GPU并行计算效率提高；
相比于小批量，对于相同的数据量，处理速度更快；
在一定范围内，一般来说，Batch Size 越大，其确定的 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/09/08/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" title="优化算法"><img class="post_bg" src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="优化算法"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/09/08/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" title="优化算法">优化算法</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-09-08T12:59:40.000Z" title="发表于 2022-09-08 20:59:40">2022-09-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">SGD、BGD、MBGD
现在所说的SGD一般都指MBGD(小批量梯度下降法Mini-batch Gradient Descent)。
三种梯度下降的方法用于更新参数，也就是当前参数等于上一时刻参数减去学习率乘以梯度。

三种方法的不同体现在计算梯度上 
假设损失函数为二次函数，那么参数θ的更新公式为

SGD（随机梯度下降法Stochastic Gradient Descent）
SGD：mini-batch gradient descent（随机梯度下降）
SGD就是每一次迭代每次只用一个样本计算mini-batch的梯度，然后对参数进行更新，是最常见的优化方法了。
&lt;img src=“https://ftp.bmp.ovh/imgs/2021/07/742b1819c08ba909.png” style=“zoom: 67%;” /
优点是速度快，缺点是可能陷入局部最优，搜索起来比较盲目，并不是每次都朝着最优的方向（因为单个样本可能噪音比较多），走的路径比较曲折（震荡）。


BGD (批梯度下降算法 Batch Gradient Descent）
计算梯度时候使用所有的数 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/09/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%A1%B6%E7%BA%A7%E6%9C%9F%E5%88%8A%E4%BC%9A%E8%AE%AE%E5%8F%8A%E5%AD%A6%E4%B9%A0%E7%BD%91%E5%9D%80/" title="计算机顶级期刊会议及学习网址"><img class="post_bg" src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机顶级期刊会议及学习网址"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/09/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%A1%B6%E7%BA%A7%E6%9C%9F%E5%88%8A%E4%BC%9A%E8%AE%AE%E5%8F%8A%E5%AD%A6%E4%B9%A0%E7%BD%91%E5%9D%80/" title="计算机顶级期刊会议及学习网址">计算机顶级期刊会议及学习网址</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-09-08T12:55:59.000Z" title="发表于 2022-09-08 20:55:59">2022-09-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">CCF推荐计算机顶会/期刊
人工智能领域最核心的四大顶会AAAI、IJCAI、ICML和NIPS，以及作为计算机视觉和自然语言为代表的CVPR和ACL这两大学术会议，也涌现了许多“后起之秀”，比如仅创立六年却有深度学习顶会“无冕之王”之称的ICLR，还有创办于1996年的大有赶超ACL之势的自然语言处理领域顶会EMNLP。




作者：爱学习的团子酱
链接：https://zhuanlan.zhihu.com/p/339490850
来源：知乎
计算机视觉顶会
1、 ICCV (International Conference on Computer Vision)
ICCV 的全称是 IEEE International Conference on Computer Vision，即国际计算机视觉大会，由IEEE主办，与计算机视觉模式识别会议（CVPR）和欧洲计算机视觉会议（ECCV）并称计算机视觉方向的三大顶级会议，被澳大利亚ICT学术会议排名和中国计算机学会等机构评为最高级别学术会议，在业内具有极高的评价。不同于在美国每年召开一次的CVPR和只在欧洲召开的ECCV，ICCV在世 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/09/08/%E4%B8%8D%E5%B9%B3%E8%A1%A1%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/" title="不平衡分类的处理方式"><img class="post_bg" src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="不平衡分类的处理方式"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/09/08/%E4%B8%8D%E5%B9%B3%E8%A1%A1%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/" title="不平衡分类的处理方式">不平衡分类的处理方式</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-09-08T12:54:11.000Z" title="发表于 2022-09-08 20:54:11">2022-09-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">如果你研究过一点机器学习和数据科学，你肯定遇到过不平衡的类分布（imbalanced class distribution）。这种情况是指：属于某一类别的观测样本的数量显著少于其它类别。
这个问题在异常检测是至关重要的的场景中很明显，例如电力盗窃、银行的欺诈交易、罕见疾病识别等。在这种情况下，利用传统机器学习算法开发出的预测模型可能会存在偏差和不准确。
发生这种情况的原因是机器学习算法通常被设计成通过减少误差来提高准确率。所以它们并没有考虑类别的分布/比例或者是类别的平衡。
这篇指南描述了使用多种采样技术来解决这种类别不平衡问题的各种方法。本文还比较了每种技术的优缺点。最后，本文作者还向我们展示了一种让你可以创建一个平衡的类分布的方法，让你可以应用专门为此设计的集成学习技术（ensemble learning technique）。本文作者为来自 KPMG 的数据分析顾问 Upasana Mukherjee。
1. 不平衡数据集面临的挑战
当今公用事业行业面临的主要挑战之一就是电力盗窃。电力盗窃是全球第三大盗窃形式。越来越多的公用事业公司倾向于使用高级的数据分析技术和机器学习算法来识别 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/#content-inner">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/#content-inner">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/#content-inner">6</a><a class="extend next" rel="next" href="/page/4/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s1.ax1x.com/2022/09/08/vbOo6J.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CJH</div><div class="author-info__description">Hello,my friends</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">51</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/cjh0220"><i class="fab fa-github"></i><span>Gihhub</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/cjh0220" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1005741898@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/09/09/%E8%B5%84%E6%9C%AC%E7%A6%80%E8%B5%8B/" title="资本禀赋"><img src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="资本禀赋"/></a><div class="content"><a class="title" href="/2022/09/09/%E8%B5%84%E6%9C%AC%E7%A6%80%E8%B5%8B/" title="资本禀赋">资本禀赋</a><time datetime="2022-09-09T01:54:14.000Z" title="发表于 2022-09-09 09:54:14">2022-09-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/09/%E5%9B%BD%E8%B5%9B2020B%E6%B2%99%E6%BC%A0%E8%87%B4%E5%AF%8C%E4%B9%8B%E8%B7%AF/" title="国赛2020B沙漠致富之路"><img src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="国赛2020B沙漠致富之路"/></a><div class="content"><a class="title" href="/2022/09/09/%E5%9B%BD%E8%B5%9B2020B%E6%B2%99%E6%BC%A0%E8%87%B4%E5%AF%8C%E4%B9%8B%E8%B7%AF/" title="国赛2020B沙漠致富之路">国赛2020B沙漠致富之路</a><time datetime="2022-09-09T01:47:17.000Z" title="发表于 2022-09-09 09:47:17">2022-09-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/09/%E5%9B%BE%E8%AE%BA/" title="图论"><img src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图论"/></a><div class="content"><a class="title" href="/2022/09/09/%E5%9B%BE%E8%AE%BA/" title="图论">图论</a><time datetime="2022-09-09T01:45:36.000Z" title="发表于 2022-09-09 09:45:36">2022-09-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/09/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" title="时间序列模型"><img src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="时间序列模型"/></a><div class="content"><a class="title" href="/2022/09/09/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" title="时间序列模型">时间序列模型</a><time datetime="2022-09-09T01:44:24.000Z" title="发表于 2022-09-09 09:44:24">2022-09-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/08/%E6%8E%92%E9%98%9F%E8%AE%BA/" title="排队论"><img src="https://s1.ax1x.com/2022/09/08/vqpCng.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="排队论"/></a><div class="content"><a class="title" href="/2022/09/08/%E6%8E%92%E9%98%9F%E8%AE%BA/" title="排队论">排队论</a><time datetime="2022-09-08T15:17:01.000Z" title="发表于 2022-09-08 23:17:01">2022-09-08</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%85%B6%E4%BB%96/"><span class="card-category-list-name">其他</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%8F%AF%E6%8B%93%E5%AD%A6/"><span class="card-category-list-name">可拓学</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"><span class="card-category-list-name">基础知识</span><span class="card-category-list-count">5</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"><span class="card-category-list-name">推荐算法</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"><span class="card-category-list-name">数学建模</span><span class="card-category-list-count">20</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">机器学习</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">深度学习</span><span class="card-category-list-count">13</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/GBDT%E7%AE%97%E6%B3%95/" style="font-size: 1.1em; color: #999">GBDT算法</a> <a href="/tags/Latex/" style="font-size: 1.1em; color: #999">Latex</a> <a href="/tags/XGbooost/" style="font-size: 1.1em; color: #999">XGbooost</a> <a href="/tags/YOLO/" style="font-size: 1.1em; color: #999">YOLO</a> <a href="/tags/markdown/" style="font-size: 1.1em; color: #999">markdown</a> <a href="/tags/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" style="font-size: 1.1em; color: #999">优化算法</a> <a href="/tags/%E5%85%B6%E4%BB%96/" style="font-size: 1.1em; color: #999">其他</a> <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 1.1em; color: #999">决策树</a> <a href="/tags/%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/" style="font-size: 1.1em; color: #999">分析模型</a> <a href="/tags/%E5%8D%9A%E5%BC%88%E6%A8%A1%E5%9E%8B/" style="font-size: 1.1em; color: #999">博弈模型</a> <a href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F/" style="font-size: 1.1em; color: #999">卷积神经</a> <a href="/tags/%E5%8F%AF%E6%8B%93%E5%AD%A6/" style="font-size: 1.1em; color: #999">可拓学</a> <a href="/tags/%E5%9B%BD%E8%B5%9B%E5%8E%9F%E9%A2%98/" style="font-size: 1.1em; color: #999">国赛原题</a> <a href="/tags/%E5%9B%BE%E8%AE%BA/" style="font-size: 1.1em; color: #999">图论</a> <a href="/tags/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/" style="font-size: 1.1em; color: #999">差异分析</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 1.1em; color: #999">归一化</a> <a href="/tags/%E6%84%9F%E7%9F%A5%E6%9C%BA/" style="font-size: 1.1em; color: #999">感知机</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 1.1em; color: #999">损失函数</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%87%BD%E6%95%B0%E6%B1%82%E5%AF%BC/" style="font-size: 1.1em; color: #999">损失函数函数求导</a> <a href="/tags/%E6%8E%92%E9%98%9F%E6%A8%A1%E5%9E%8B/" style="font-size: 1.1em; color: #999">排队模型</a> <a href="/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/" style="font-size: 1.1em; color: #999">推荐算法</a> <a href="/tags/%E6%8F%8F%E8%BF%B0%E6%80%A7%E7%BB%9F%E8%AE%A1/" style="font-size: 1.1em; color: #999">描述性统计</a> <a href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" style="font-size: 1.1em; color: #999">支持向量机</a> <a href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" style="font-size: 1.3em; color: #99a1ac">数学建模</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" style="font-size: 1.5em; color: #99a9bf">数据处理</a> <a href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/" style="font-size: 1.1em; color: #999">时间序列</a> <a href="/tags/%E6%9C%9F%E5%88%8A%E4%BC%9A%E8%AE%AE/" style="font-size: 1.1em; color: #999">期刊会议</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%A6%81/" style="font-size: 1.1em; color: #999">模型概要</a> <a href="/tags/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB/" style="font-size: 1.1em; color: #999">模拟退火</a> <a href="/tags/%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C/" style="font-size: 1.1em; color: #999">残差网络</a> <a href="/tags/%E6%B7%B1%E5%AD%A6%E8%B0%83%E5%8F%82/" style="font-size: 1.1em; color: #999">深学调参</a> <a href="/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" style="font-size: 1.1em; color: #999">激活函数</a> <a href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" style="font-size: 1.1em; color: #999">特征工程</a> <a href="/tags/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/" style="font-size: 1.1em; color: #999">环境变量</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 1.1em; color: #999">目标检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 1.1em; color: #999">神经网络</a> <a href="/tags/%E7%B2%92%E5%AD%90%E7%BE%A4/" style="font-size: 1.1em; color: #999">粒子群</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/" style="font-size: 1.1em; color: #999">聚类算法</a> <a href="/tags/%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95/" style="font-size: 1.1em; color: #999">规划算法</a> <a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 1.1em; color: #999">论文</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/09/"><span class="card-archive-list-date">九月 2022</span><span class="card-archive-list-count">51</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">51</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2022-09-07T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-09-09T01:58:00.768Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://s1.ax1x.com/2022/09/08/vqcdVs.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By CJH</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">欢迎欢迎，热烈欢迎</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#subtitle", {
      strings: ["今日事，今日畢","多喝热水","不要熬夜"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '今日事，今日畢'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>