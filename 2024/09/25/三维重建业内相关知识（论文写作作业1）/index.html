<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>三维重建业内相关知识（论文写作作业1） | CJH's blog</title><meta name="keywords" content="业内知识"><meta name="author" content="CJH"><meta name="copyright" content="CJH"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="课题：三维重建 &#x2F; 心脏超声的三维重建1 顶级期刊或会议1.1 CVPR（会议）全称：IEEE Conference on Computer Vision and Pattern Recognition 出版商：IEEE 领域：计算机视觉和模式识别 时间：一年一度 CCF A类 1.2 ICCV （会议）全称：International Conference on Computer Vision">
<meta property="og:type" content="article">
<meta property="og:title" content="三维重建业内相关知识（论文写作作业1）">
<meta property="og:url" content="http://cjh0220.github.io/2024/09/25/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E4%B8%9A%E5%86%85%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%EF%BC%88%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E4%BD%9C%E4%B8%9A1%EF%BC%89/index.html">
<meta property="og:site_name" content="CJH&#39;s blog">
<meta property="og:description" content="课题：三维重建 &#x2F; 心脏超声的三维重建1 顶级期刊或会议1.1 CVPR（会议）全称：IEEE Conference on Computer Vision and Pattern Recognition 出版商：IEEE 领域：计算机视觉和模式识别 时间：一年一度 CCF A类 1.2 ICCV （会议）全称：International Conference on Computer Vision">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s3.bmp.ovh/imgs/2024/08/08/ae1ec012ccabe947.png">
<meta property="article:published_time" content="2024-09-25T11:20:37.000Z">
<meta property="article:modified_time" content="2024-09-25T11:21:18.173Z">
<meta property="article:author" content="CJH">
<meta property="article:tag" content="业内知识">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s3.bmp.ovh/imgs/2024/08/08/ae1ec012ccabe947.png"><link rel="shortcut icon" href="/img/CJH.png"><link rel="canonical" href="http://cjh0220.github.io/2024/09/25/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E4%B8%9A%E5%86%85%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%EF%BC%88%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E4%BD%9C%E4%B8%9A1%EF%BC%89/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '三维重建业内相关知识（论文写作作业1）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-25 19:21:18'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s1.ax1x.com/2022/09/08/vbOo6J.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">128</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">101</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">25</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s3.bmp.ovh/imgs/2024/08/08/ae1ec012ccabe947.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">CJH's blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">三维重建业内相关知识（论文写作作业1）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2024-09-25T11:20:37.000Z" title="发表于 2024-09-25 19:20:37">2024-09-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/">三维重建</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="三维重建业内相关知识（论文写作作业1）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="课题：三维重建-心脏超声的三维重建"><a href="#课题：三维重建-心脏超声的三维重建" class="headerlink" title="课题：三维重建 / 心脏超声的三维重建"></a>课题：三维重建 / 心脏超声的三维重建</h1><h1 id="1-顶级期刊或会议"><a href="#1-顶级期刊或会议" class="headerlink" title="1 顶级期刊或会议"></a>1 顶级期刊或会议</h1><h2 id="1-1-CVPR（会议）"><a href="#1-1-CVPR（会议）" class="headerlink" title="1.1 CVPR（会议）"></a>1.1 CVPR（会议）</h2><p><strong>全称：</strong>IEEE Conference on Computer Vision and Pattern Recognition</p>
<p><strong>出版商：</strong>IEEE</p>
<p><strong>领域：</strong>计算机视觉和模式识别</p>
<p><strong>时间：</strong>一年一度</p>
<p>CCF A类</p>
<h2 id="1-2-ICCV-（会议）"><a href="#1-2-ICCV-（会议）" class="headerlink" title="1.2 ICCV （会议）"></a>1.2 ICCV （会议）</h2><p><strong>全称：</strong>International Conference on Computer Vision</p>
<p><strong>出版商：</strong>IEEE</p>
<p><strong>领域：</strong>计算机视觉</p>
<p><strong>时间：</strong>两年一度</p>
<p>CCF A类</p>
<h2 id="1-3-ECCV（会议）"><a href="#1-3-ECCV（会议）" class="headerlink" title="1.3 ECCV（会议）"></a>1.3 ECCV（会议）</h2><p><strong>全称：</strong>European Conference on Computer Vision</p>
<p><strong>出版商：</strong>Springer Verlag</p>
<p><strong>领域：</strong>计算机视觉</p>
<p><strong>时间：</strong>每两年召开一次，与ICCV正好错开</p>
<p>CCF B类</p>
<h2 id="1-4-WACV"><a href="#1-4-WACV" class="headerlink" title="1.4 WACV"></a>1.4 WACV</h2><p><strong>全称：</strong>IEEE Winter Conference on Applications of Computer Vision）</p>
<p><strong>领域：</strong>计算机视觉</p>
<p><strong>时间：</strong>每年冬天，美国本土</p>
<p>CCF B类</p>
<h2 id="1-5-TPAMI（期刊）"><a href="#1-5-TPAMI（期刊）" class="headerlink" title="1.5 TPAMI（期刊）"></a>1.5 TPAMI（期刊）</h2><p><strong>全称：</strong>IEEE Transactions on Pattern Analysis and Machine Intelligence</p>
<p><strong>出版商：</strong>IEEE</p>
<p><strong>领域：</strong>计算机科学</p>
<p><strong>影响因子：</strong>20.8</p>
<p>SCI升级版 计算机科学1区，SCI基础版 工程技术1区,CCF A类, 中科院1区。</p>
<h1 id="2-代表性和前沿论文的引文信息"><a href="#2-代表性和前沿论文的引文信息" class="headerlink" title="2 代表性和前沿论文的引文信息"></a>2 代表性和前沿论文的引文信息</h1><h2 id="2-1-Deep-Residual-Learning-for-Image-Recognition"><a href="#2-1-Deep-Residual-Learning-for-Image-Recognition" class="headerlink" title="2.1 Deep Residual Learning for Image Recognition"></a>2.1 Deep Residual Learning for Image Recognition</h2><p>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun;Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770-778</p>
<h2 id="2-2-OReX-Object-Reconstruction-From-Planar-Cross-Sections-Using-Neural-Fields"><a href="#2-2-OReX-Object-Reconstruction-From-Planar-Cross-Sections-Using-Neural-Fields" class="headerlink" title="2.2 OReX: Object Reconstruction From Planar Cross-Sections Using Neural Fields"></a>2.2 OReX: Object Reconstruction From Planar Cross-Sections Using Neural Fields</h2><p><strong>Haim Sawdayee, Amir Vaxman, Amit H. Bermano</strong>; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023, pp. 20854-20862</p>
<h2 id="2-3-3D-R2N2-A-Unified-Approach-for-Single-and-Multi-view-3D-Object-Reconstruction"><a href="#2-3-3D-R2N2-A-Unified-Approach-for-Single-and-Multi-view-3D-Object-Reconstruction" class="headerlink" title="2.3 3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction"></a>2.3 3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction</h2><p>Choy, C.B., Xu, D., Gwak, J., Chen, K., Savarese, S. (2016). 3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction. In: Leibe, B., Matas, J., Sebe, N., Welling, M. (eds) Computer Vision – ECCV 2016. ECCV 2016. Lecture Notes in Computer Science(), vol 9912. Springer, Cham. <a target="_blank" rel="noopener" href="https://doi.org/10.1007/978-3-319-46484-8_38">https://doi.org/10.1007/978-3-319-46484-8_38</a></p>
<h2 id="2-4-Pixel2Mesh-Generating-3D-Mesh-Models-from-Single-RGB-Images"><a href="#2-4-Pixel2Mesh-Generating-3D-Mesh-Models-from-Single-RGB-Images" class="headerlink" title="2.4 Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images"></a>2.4 Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images</h2><p><strong>Nanyang Wang, Yinda Zhang, Zhuwen Li, Yanwei Fu, Wei Liu, Yu-Gang Jiang</strong>; Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 52-67</p>
<h2 id="2-5-Long-short-term-memory"><a href="#2-5-Long-short-term-memory" class="headerlink" title="2.5 Long short-term memory."></a>2.5 Long short-term memory.</h2><p>Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural compu-<br>tation, 9(8):1735–1780, 1997.</p>
<h2 id="2-6-Structure-from-motion-revisited"><a href="#2-6-Structure-from-motion-revisited" class="headerlink" title="2.6 Structure-from-motion revisited"></a>2.6 Structure-from-motion revisited</h2><p>VJohannes Lutz Schönberger and Jan-Michael Frahm. Structure-from-motion revisited.<br>In Conference on Computer Vision and Pattern Recognition (CVPR), 2016.</p>
<h1 id="3-国内外顶级课题组leader信息"><a href="#3-国内外顶级课题组leader信息" class="headerlink" title="3 国内外顶级课题组leader信息"></a>3 国内外顶级课题组leader信息</h1><h2 id="3-1-沈琳琳"><a href="#3-1-沈琳琳" class="headerlink" title="3.1 沈琳琳"></a>3.1 沈琳琳</h2><p><img src="https://bdsc.szu.edu.cn/public//uploads/20230223/0d385d5409228e5831c6ed0357efbd05.png" alt="Image"></p>
<p>沈琳琳，博士，教授，博导。深圳大学大数据系统计算技术国家工程实验室副主任、计算机视觉研究所所长。</p>
<p>Email:llshen@szu.edu.cn</p>
<p>上海交通大学学士、硕士，受英国政府海外研究奖学金资助在诺丁汉大学获得博士学位，博士期间获得“国家优秀自费留学生”奖励。2015-2023连续9年被爱思唯尔出版社评为计算机学科“<strong>中国高被引学者</strong>”，2020-2022连续入围斯坦福大学“<strong>科学影响力全球前2%科学家榜单</strong>”，research.com计算机学科学者排名<strong>中国前500</strong>，世界前5000。现为深圳市“<strong>鹏城学者</strong>”特聘教授、英国诺丁汉大学计算机学院荣誉教授、宁波诺丁汉大学计算机系、温州肯恩大学计算机系访问教授、澳门大学杰出访问学者；大数据系统计算技术国家工程实验室副主任、广东省教育厅中英合作视觉信息处理实验室主任、深圳大学计算机视觉研究所所长、深圳大学医学影像智能分析与诊断研究中心主任、华为公司计算机视觉算法顾问。期刊《Cognitive Computation and Systems》常务副主编（Co-Editor-in-Chief）、《Expert Systems with Applications》副编辑（Associate Editor）。研究方向主要为深度学习理论及其在人脸识别/分析以及医学图像分析上的应用，作为负责人连续主持国家自然科学基金重大研究计划、国际合作研究、面上项目等5项，发表学术论文300余篇。</p>
<p> IEEE高级会员，入选江西省“双千计划”创新领军人才（短期）、广东省高校千百十工程培养对象（省级），深圳市高层次“地方领军人才”、深圳市海外高层次“孔雀计划”人才，深圳市十佳青年教师。科研成果先后获得吴文俊人工智能自然科学奖，中国电子学会、广东省和深圳市自然科学奖。人脸识别论文曾获国际期刊《Image and Vision Computing》最多他引论文奖。开发的人脸识别算法曾获ICPR算法测试亚军，开发的细胞荧光图像分类算法连续获得IEEE ICIP 2013、ICPR 2016国际细胞图像分类算法大赛冠军，目标检测算法获得MICCAI 2018细胞核检测比赛季军、2021年科大迅飞遥感影像典型目标提取挑战赛决赛季军。</p>
<p>Google Scholar 引用 10585，H指数50  <em><a target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=AZ_y9HgAAAAJ">https://scholar.google.com/citations?user=AZ_y9HgAAAAJ</a></em></p>
<p>所有论文 DBLP 网址： <em><a target="_blank" rel="noopener" href="https://dblp.org/pid/88/5607.html">https://dblp.org/pid/88/5607.html</a></em></p>
<p>项目和代码网址：        <em><a target="_blank" rel="noopener" href="http://github.com/cvi-szu">http://github.com/cvi-szu</a></em></p>
<h2 id="3-2-Prof-Dr-Marc-Pollefeys"><a href="#3-2-Prof-Dr-Marc-Pollefeys" class="headerlink" title="3.2 Prof. Dr. Marc Pollefeys"></a>3.2 Prof. Dr. Marc Pollefeys</h2><p><img src="https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=YYH0BjEAAAAJ&amp;citpid=3" alt="Marc Pollefeys"></p>
<p>苏黎世联邦理工学院和微软苏黎世混合现实和人工智能实验室主任</p>
<p><a target="_blank" rel="noopener" href="https://cvg.ethz.ch/team/Prof-Dr-Marc-Pollefeys">Computer Vision and Geometry Group | Prof. Dr. Marc Pollefeys (ethz.ch)</a></p>
<p><strong>Short Bio</strong></p>
<p>Marc Pollefeys is a Professor of Computer Science at ETH Zurich and the Director of the Microsoft Mixed Reality and AI Lab in Zurich where he works with a team of scientists and engineers to develop advanced perception capabilities for HoloLens and Mixed Reality. He was elected Fellow of the IEEE in 2012. He obtained his PhD from the KU Leuven in 1999 and was a professor at UNC Chapel Hill before joining ETH Zurich.</p>
<p>He is best known for his work in 3D computer vision, having been the first to develop a software pipeline to automatically turn photographs into 3D models, but also works on robotics, graphics and machine learning problems. Other noteworthy projects he worked on are real-time 3D scanning with mobile devices, a real-time pipeline for 3D reconstruction of cities from vehicle mounted-cameras, camera-based self-driving cars and the first fully autonomous vision-based drone. Most recently his academic research has focused on combining 3D reconstruction with semantic scene understanding.</p>
<p><strong>Curriculum vitae -</strong> short version [<a target="_blank" rel="noopener" href="https://people.inf.ethz.ch/pomarc/2021_CV_Marc Pollefeys_2pages.pdf">pdf</a>] extended version<a target="_blank" rel="noopener" href="https://people.inf.ethz.ch/pomarc/CVmp.pdf-webpage_new - extended.pdf">[pdf]</a></p>
<p><strong>Research interests</strong></p>
<p>Computer vision; 3D-from-video; (self-)calibration; structure-from-motion; simultaneous-localization and mapping (SLAM); camera tracking; camera networks; active vision; robot vision; multiple view geometry; omnidirectional vision; projector-camera systems; image-based modeling and rendering; video-based rendering; computational photography; image and video analysis; applications of computer vision to archaeology, urban modeling, terrain modeling, human-computer interaction, robotics, entertainment, medecine, etc.<br><a target="_blank" rel="noopener" href="https://people.inf.ethz.ch/pomarc/research.html">[see research page]</a>  </p>
<h2 id="3-3-Michael-Kaess"><a href="#3-3-Michael-Kaess" class="headerlink" title="3.3 Michael Kaess"></a>3.3 Michael Kaess</h2><p><img src="https://www.cs.cmu.edu/~kaess/images/kaess.jpg" alt="My picture"></p>
<p>卡内基梅隆大学Robot Perception Lab</p>
<p><strong>Associate Professor</strong><br>Robotics Institute (<a target="_blank" rel="noopener" href="https://www.ri.cmu.edu/">RI</a>)<br>School of Computer Science (<a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/">SCS</a>)<br>Carnegie Mellon University (<a target="_blank" rel="noopener" href="https://www.cmu.edu/">CMU</a>)</p>
<p>Field Robotics Center (<a target="_blank" rel="noopener" href="https://frc.ri.cmu.edu/">FRC</a>) and Computer Vision Group (<a target="_blank" rel="noopener" href="https://vision.cs.cmu.edu/index.html">CV</a>)<br><strong>Director</strong>, Robot Perception Lab (<a target="_blank" rel="noopener" href="https://rpl.ri.cmu.edu/">RPL</a>)</p>
<p>5000 Forbes Ave, Room CIC LL42</p>
<p>Pittsburgh, PA 15213-3890</p>
<p>Phone: (412)268-6905, Email: kaess@cmu.edu</p>
<p>I am interested in mobile robot autonomy. One of the first problems encountered when robots operate outside controlled factory and research environments is the need to perceive their surroundings. My research focuses on efficient inference at the connection of linear algebra and probabilistic graphical models for 3D mapping and localization.</p>
<p>I have previously been a Research Scientist and a Postdoctoral Associate at the Massachusetts Institute of Technology (MIT), in <a target="_blank" rel="noopener" href="https://meche.mit.edu/people/faculty/JLEONARD@MIT.EDU">John Leonard</a>‘s Marine Robotics Lab. In 2008 I have received my PhD in Computer Science from the Georgia Institute of Technology, advised by <a target="_blank" rel="noopener" href="https://www.cc.gatech.edu/~dellaert/">Frank Dellaert</a>.</p>
<h1 id="4-国内外研究现状"><a href="#4-国内外研究现状" class="headerlink" title="4 国内外研究现状"></a>4 国内外研究现状</h1><p>随着科学界的跨国交流与合作越来越密切，我认为研究分为国内国外是不具备科学性的。按照时间以及表现得分的研究现状研究分析才具有逻辑性与科学性。下面我将简单展示国内外在三维重建中的创新型研究。</p>
<h2 id="4-1-国内"><a href="#4-1-国内" class="headerlink" title="4.1 国内"></a>4.1 国内</h2><p>对于3D重建这项任务而言，我们国家位于世界前列。比较具有创新性的有：</p>
<p>Wang N在2018年提出了Pixel2Mesh，可通过单视图生成3d网格模型。</p>
<p>哈尔滨工业大学的Haozhe Xie在2019年提出了Pix2Vox，仅通过当单个或多个视角结合了上下文融合技术即可生成质量高的体素3D模型。同时在2020年提出了Pix2Vox++，支持更高分辨率的重建。</p>
<p>清华大学的Haoqiang Fan等人提出了PSGN，从单个图像生成点云网络。</p>
<p>中国科学技术大学与不列颠哥伦比亚大学Dan Wang等人在2021年提出了VoiT，即利用tansformer进行多视图三维重建。</p>
<p>每年都有大量的国人在顶会顶刊中发布新的方法以及对现有方法的改进。国家也投入了大量的政策支持和经济支持。通过企业与高效结合，科研与产业结合推动技术发展。比如近期热门的萝卜快跑中智能驾驶技术，就有对三维场景重建以及场景理解的技术。</p>
<h2 id="4-2-国外"><a href="#4-2-国外" class="headerlink" title="4.2 国外"></a>4.2 国外</h2><p>2016年Choy CB提出的3D-R2N2模型，使得人们高度关注当今流行的网络架构在三维重建的使用。通过接收对象及其边界框的一张或多张图像作为输入，在体素空间中生成对象的 3D 模型。 他们提出了两种网络结构； 第一个模型没有返回连接并且更浅。 第二种模型更深并且具有返回连接。 两种模型都具有三个主要部分。 这些部分包括：编码器、3D 卷积 LSTM 和解码器。 编码器部分将每个输入图像编码为1024维向量。 然后将该向量输入 3D 卷积 LSTM，该 LSTM 由 4 × 4 × 4 修改后的 LSTM 单元网格组成。 </p>
<p>2017年Tatarchenko提出的OGN模型，八叉树生成网络为业内带来对于三维表示的启迪。八叉树生成网络具有基于编码器-解码器的结构。 编码阶段之后，解码器生成粗略的低分辨率 3D 模型。 然后通过一些八叉树生成层来提高分辨率。 这些层中的每一层根据每个体素是否被占用将其分为八个部分。 如果体素为空，则图层不会对其进行细分，从而节省内存。 另一方面，如果输入体素被占用，则它被分成更小的部分。 </p>
<p>2019年Park JJ等人提出了DeepSDF，使用三维的隐式表达来进行深度学习，得到了很好的结果。</p>
<p>对于场景的三维重建如：NeRF（2020 UC Berkeley）和3D高斯泼溅（2023 法国蔚蓝海岸大学）相关的论文也在顶刊顶会频繁刷榜。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://cjh0220.github.io">CJH</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://cjh0220.github.io/2024/09/25/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E4%B8%9A%E5%86%85%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%EF%BC%88%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E4%BD%9C%E4%B8%9A1%EF%BC%89/">http://cjh0220.github.io/2024/09/25/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E4%B8%9A%E5%86%85%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%EF%BC%88%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E4%BD%9C%E4%B8%9A1%EF%BC%89/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://cjh0220.github.io" target="_blank">CJH's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%B8%9A%E5%86%85%E7%9F%A5%E8%AF%86/">业内知识</a></div><div class="post_share"><div class="social-share" data-image="https://s3.bmp.ovh/imgs/2024/08/08/ae1ec012ccabe947.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/10/08/VAE%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81/"><img class="prev-cover" src="https://s3.bmp.ovh/imgs/2024/09/29/00ef3f438a5f7577.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">VAE变分自编码</div></div></a></div><div class="next-post pull-right"><a href="/2024/09/18/%E6%B7%B1%E5%BA%A6%E5%9B%BEDepth-Map/"><img class="next-cover" src="https://s3.bmp.ovh/imgs/2024/09/09/ca630095c9ea5d25.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">深度图Depth_Map</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s1.ax1x.com/2022/09/08/vbOo6J.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CJH</div><div class="author-info__description">Hello,my friends</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">128</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">101</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">25</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/cjh0220"><i class="fab fa-github"></i><span>Gihhub</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/cjh0220" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1005741898@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%BE%E9%A2%98%EF%BC%9A%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA-%E5%BF%83%E8%84%8F%E8%B6%85%E5%A3%B0%E7%9A%84%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA"><span class="toc-number">1.</span> <span class="toc-text">课题：三维重建 &#x2F; 心脏超声的三维重建</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E9%A1%B6%E7%BA%A7%E6%9C%9F%E5%88%8A%E6%88%96%E4%BC%9A%E8%AE%AE"><span class="toc-number">2.</span> <span class="toc-text">1 顶级期刊或会议</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-CVPR%EF%BC%88%E4%BC%9A%E8%AE%AE%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">1.1 CVPR（会议）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-ICCV-%EF%BC%88%E4%BC%9A%E8%AE%AE%EF%BC%89"><span class="toc-number">2.2.</span> <span class="toc-text">1.2 ICCV （会议）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-ECCV%EF%BC%88%E4%BC%9A%E8%AE%AE%EF%BC%89"><span class="toc-number">2.3.</span> <span class="toc-text">1.3 ECCV（会议）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-WACV"><span class="toc-number">2.4.</span> <span class="toc-text">1.4 WACV</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-TPAMI%EF%BC%88%E6%9C%9F%E5%88%8A%EF%BC%89"><span class="toc-number">2.5.</span> <span class="toc-text">1.5 TPAMI（期刊）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E4%BB%A3%E8%A1%A8%E6%80%A7%E5%92%8C%E5%89%8D%E6%B2%BF%E8%AE%BA%E6%96%87%E7%9A%84%E5%BC%95%E6%96%87%E4%BF%A1%E6%81%AF"><span class="toc-number">3.</span> <span class="toc-text">2 代表性和前沿论文的引文信息</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-Deep-Residual-Learning-for-Image-Recognition"><span class="toc-number">3.1.</span> <span class="toc-text">2.1 Deep Residual Learning for Image Recognition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-OReX-Object-Reconstruction-From-Planar-Cross-Sections-Using-Neural-Fields"><span class="toc-number">3.2.</span> <span class="toc-text">2.2 OReX: Object Reconstruction From Planar Cross-Sections Using Neural Fields</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-3D-R2N2-A-Unified-Approach-for-Single-and-Multi-view-3D-Object-Reconstruction"><span class="toc-number">3.3.</span> <span class="toc-text">2.3 3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-Pixel2Mesh-Generating-3D-Mesh-Models-from-Single-RGB-Images"><span class="toc-number">3.4.</span> <span class="toc-text">2.4 Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-Long-short-term-memory"><span class="toc-number">3.5.</span> <span class="toc-text">2.5 Long short-term memory.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-6-Structure-from-motion-revisited"><span class="toc-number">3.6.</span> <span class="toc-text">2.6 Structure-from-motion revisited</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E5%9B%BD%E5%86%85%E5%A4%96%E9%A1%B6%E7%BA%A7%E8%AF%BE%E9%A2%98%E7%BB%84leader%E4%BF%A1%E6%81%AF"><span class="toc-number">4.</span> <span class="toc-text">3 国内外顶级课题组leader信息</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E6%B2%88%E7%90%B3%E7%90%B3"><span class="toc-number">4.1.</span> <span class="toc-text">3.1 沈琳琳</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-Prof-Dr-Marc-Pollefeys"><span class="toc-number">4.2.</span> <span class="toc-text">3.2 Prof. Dr. Marc Pollefeys</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-Michael-Kaess"><span class="toc-number">4.3.</span> <span class="toc-text">3.3 Michael Kaess</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E5%9B%BD%E5%86%85%E5%A4%96%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6"><span class="toc-number">5.</span> <span class="toc-text">4 国内外研究现状</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-%E5%9B%BD%E5%86%85"><span class="toc-number">5.1.</span> <span class="toc-text">4.1 国内</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-%E5%9B%BD%E5%A4%96"><span class="toc-number">5.2.</span> <span class="toc-text">4.2 国外</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/10/23/BRDF/" title="BRDF"><img src="https://s3.bmp.ovh/imgs/2024/08/08/ae1ec012ccabe947.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="BRDF"/></a><div class="content"><a class="title" href="/2024/10/23/BRDF/" title="BRDF">BRDF</a><time datetime="2024-10-23T09:09:50.000Z" title="发表于 2024-10-23 17:09:50">2024-10-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/23/UVmapping/" title="UVmapping"><img src="https://s3.bmp.ovh/imgs/2024/10/20/da943600cfa91298.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="UVmapping"/></a><div class="content"><a class="title" href="/2024/10/23/UVmapping/" title="UVmapping">UVmapping</a><time datetime="2024-10-23T09:07:11.000Z" title="发表于 2024-10-23 17:07:11">2024-10-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/11/MVSNet/" title="MVSNet"><img src="https://s3.bmp.ovh/imgs/2024/10/11/448b7fc6cc6a415b.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MVSNet"/></a><div class="content"><a class="title" href="/2024/10/11/MVSNet/" title="MVSNet">MVSNet</a><time datetime="2024-10-11T08:09:42.000Z" title="发表于 2024-10-11 16:09:42">2024-10-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/08/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E8%AF%84%E4%BC%B0%E6%A0%87%E5%87%86/" title="三维重建的损失函数和评估标准"><img src="https://s3.bmp.ovh/imgs/2024/10/08/249610cbabf14611.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="三维重建的损失函数和评估标准"/></a><div class="content"><a class="title" href="/2024/10/08/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E8%AF%84%E4%BC%B0%E6%A0%87%E5%87%86/" title="三维重建的损失函数和评估标准">三维重建的损失函数和评估标准</a><time datetime="2024-10-08T01:48:23.000Z" title="发表于 2024-10-08 09:48:23">2024-10-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/08/VAE%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81/" title="VAE变分自编码"><img src="https://s3.bmp.ovh/imgs/2024/09/29/00ef3f438a5f7577.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VAE变分自编码"/></a><div class="content"><a class="title" href="/2024/10/08/VAE%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81/" title="VAE变分自编码">VAE变分自编码</a><time datetime="2024-10-08T01:47:46.000Z" title="发表于 2024-10-08 09:47:46">2024-10-08</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://s3.bmp.ovh/imgs/2024/08/08/ae1ec012ccabe947.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By CJH</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">欢迎欢迎，热烈欢迎</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>